{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.231405</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.157025</td>\n",
       "      <td>0.441938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.441938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.185950</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.185950</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231405</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.206612</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age        bp    sg   al   su  rbc   pc  pcc   ba       bgr  ...  \\\n",
       "0    0.522727  0.230769  0.75  0.2  0.0  1.0  1.0  0.0  0.0  0.211538  ...   \n",
       "1    0.056818  0.000000  0.75  0.8  0.0  1.0  1.0  0.0  0.0  0.269309  ...   \n",
       "2    0.681818  0.230769  0.25  0.4  0.6  1.0  1.0  0.0  0.0  0.856838  ...   \n",
       "3    0.522727  0.153846  0.00  0.8  0.0  1.0  0.0  1.0  0.0  0.202991  ...   \n",
       "4    0.556818  0.230769  0.25  0.4  0.0  1.0  1.0  0.0  0.0  0.179487  ...   \n",
       "..        ...       ...   ...  ...  ...  ...  ...  ...  ...       ...  ...   \n",
       "394  0.602273  0.230769  0.75  0.0  0.0  1.0  1.0  0.0  0.0  0.252137  ...   \n",
       "395  0.454545  0.153846  1.00  0.0  0.0  1.0  1.0  0.0  0.0  0.113248  ...   \n",
       "396  0.113636  0.230769  0.75  0.0  0.0  1.0  1.0  0.0  0.0  0.166667  ...   \n",
       "397  0.170455  0.076923  1.00  0.0  0.0  1.0  1.0  0.0  0.0  0.196581  ...   \n",
       "398  0.636364  0.230769  1.00  0.0  0.0  1.0  1.0  0.0  0.0  0.232906  ...   \n",
       "\n",
       "          pcv      wbcc      rbcc  htn   dm  cad  appet   pe  ane  class  \n",
       "0    0.777778  0.231405  0.525424  1.0  1.0  0.0    0.0  0.0  0.0    0.0  \n",
       "1    0.644444  0.157025  0.441938  0.0  0.0  0.0    0.0  0.0  0.0    0.0  \n",
       "2    0.488889  0.219008  0.441938  0.0  1.0  0.0    1.0  0.0  1.0    0.0  \n",
       "3    0.511111  0.185950  0.305085  1.0  0.0  0.0    1.0  1.0  1.0    0.0  \n",
       "4    0.577778  0.210744  0.423729  0.0  0.0  0.0    0.0  0.0  0.0    0.0  \n",
       "..        ...       ...       ...  ...  ...  ...    ...  ...  ...    ...  \n",
       "394  0.844444  0.185950  0.474576  0.0  0.0  0.0    0.0  0.0  0.0    1.0  \n",
       "395  1.000000  0.231405  0.694915  0.0  0.0  0.0    0.0  0.0  0.0    1.0  \n",
       "396  0.888889  0.181818  0.559322  0.0  0.0  0.0    0.0  0.0  0.0    1.0  \n",
       "397  0.933333  0.206612  0.644068  0.0  0.0  0.0    0.0  0.0  0.0    1.0  \n",
       "398  0.977778  0.190083  0.677966  0.0  0.0  0.0    0.0  0.0  0.0    1.0  \n",
       "\n",
       "[399 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the cleaned dataset from assignment 1\n",
    "df = pd.read_csv(\"scaled_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class']) \n",
    "y = df['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies over 5 iterations: [0.9416666666666667, 0.975, 0.9416666666666667, 0.9416666666666667, 0.9583333333333334]\n",
      "Average Accuracy: 95.17%\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "r = 5  #5 times repeat\n",
    "test_size = 0.3\n",
    "accuracies = []\n",
    "\n",
    "# repeated random sampling\n",
    "for i in range(r):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None)\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# average accuracy\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(f\"Accuracies over {r} iterations: {accuracies}\")\n",
    "print(f\"Average Accuracy: {average_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Fold 1: Accuracy = 1.0000, ROC AUC = 1.0000\n",
      "Fold 2/5\n",
      "Fold 2: Accuracy = 0.8750, ROC AUC = 0.9986\n",
      "Fold 3/5\n",
      "Fold 3: Accuracy = 0.9250, ROC AUC = 0.9987\n",
      "Fold 4/5\n",
      "Fold 4: Accuracy = 0.9750, ROC AUC = 1.0000\n",
      "Fold 5/5\n",
      "Fold 5: Accuracy = 0.9620, ROC AUC = 0.9981\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 94.74%\n",
      "Average ROC AUC: 0.9991\n"
     ]
    }
   ],
   "source": [
    "# Convert X (DataFrame) to a NumPy array before creating a PyTorch tensor\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32) \n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)  \n",
    "\n",
    "\n",
    "# Define the MLP structure\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)  # First hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 1)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 24\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "k_folds = 5\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "roc_aucs = []\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_tensor)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test = X_tensor[train_idx], X_tensor[test_idx]\n",
    "    y_train, y_test = y_tensor[train_idx], y_tensor[test_idx]\n",
    "    \n",
    "    # Create DataLoader for batching\n",
    "    train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = MLP(input_size=input_size)\n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X).squeeze()  # Forward pass\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).squeeze()  # Predictions\n",
    "        y_pred_class = (y_pred >= 0.5).float()  # Threshold for binary classification\n",
    "        \n",
    "        # Accuracy\n",
    "        acc = accuracy_score(y_test, y_pred_class)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        # ROC AUC\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Fold {fold + 1}: Accuracy = {acc:.4f}, ROC AUC = {roc_auc:.4f}\")\n",
    "\n",
    "# Report average results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracies) * 100:.2f}%\")\n",
    "print(f\"Average ROC AUC: {np.mean(roc_aucs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/jg4kg4r559q5r2lgb1by5l7h0000gn/T/ipykernel_2458/2087332290.py:7: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super(RBFLayer, self).__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.3648 - loss: 0.6982\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.6660 - loss: 0.6923\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7555 - loss: 0.6910\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.8487 - loss: 0.6874\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.7647 - loss: 0.6855\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6418 - loss: 0.6822\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.5499 - loss: 0.6814\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.6105 - loss: 0.6758\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.5537 - loss: 0.6770\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.6009 - loss: 0.6700\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.6070 - loss: 0.6682\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.6179 - loss: 0.6645\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.5518 - loss: 0.6677\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.6009 - loss: 0.6597\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.6115 - loss: 0.6537\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.5443 - loss: 0.6588\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.6560 - loss: 0.6426\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.6529 - loss: 0.6448\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7167 - loss: 0.6360\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7663 - loss: 0.6349\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.8291 - loss: 0.6288\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.8526 - loss: 0.6244\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8863 - loss: 0.6139\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9276 - loss: 0.6076\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.9156 - loss: 0.6036\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.9129 - loss: 0.5891\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9216 - loss: 0.5777\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9095 - loss: 0.5705\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.9246 - loss: 0.5565\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.9003 - loss: 0.5503\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.8911 - loss: 0.5432\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.9192 - loss: 0.5194\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.9147 - loss: 0.5070\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.8780 - loss: 0.5050\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.9160 - loss: 0.4743\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9161 - loss: 0.4653\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.9162 - loss: 0.4507\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8988 - loss: 0.4554\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276us/step - accuracy: 0.9157 - loss: 0.4245\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.9058 - loss: 0.4200\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.9322 - loss: 0.3888\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8984 - loss: 0.3975\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9173 - loss: 0.3801\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.8990 - loss: 0.3754\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.8883 - loss: 0.3730\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.9056 - loss: 0.3620\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.9172 - loss: 0.3617\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9347 - loss: 0.3279\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.9423 - loss: 0.3230\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9478 - loss: 0.3052\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "Confusion Matrix:\n",
      "[[118  13]\n",
      " [  0  69]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95       131\n",
      "         1.0       0.84      1.00      0.91        69\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.92      0.95      0.93       200\n",
      "weighted avg       0.95      0.94      0.94       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data: 50% training, 50% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define a custom RBF Layer\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, num_centers, gamma=1.0, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.num_centers = num_centers\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.centers = self.add_weight(\n",
    "            shape=(self.num_centers, input_shape[-1]),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = tf.expand_dims(inputs, axis=1) - self.centers\n",
    "        l2 = tf.reduce_sum(tf.square(diff), axis=-1)\n",
    "        return tf.exp(-self.gamma * l2)\n",
    "\n",
    "# Build the RBFNN model\n",
    "model = Sequential([\n",
    "    RBFLayer(num_centers=10, gamma=0.5, input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Confusion Matrix and Metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
